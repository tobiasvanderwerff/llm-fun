{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea: ask questions to an LLM about a codebase, using embeddings. Feeding the entire codebase to the LLM would exceed it's maximum context length, so embeddings are used to select those pieces of text which are most relevant to the input prompt/question. A single embedding represents a chunk of the codebase, e.g. 1000 tokens of it, turned into a vector representation using OpenAI's embeddings API. \n",
    "\n",
    "The pipeline then goes as follows:\n",
    "- ask a question\n",
    "- match the question to the most similar embeddings (e.g. top 5) \n",
    "- add the pieces of text corresponding to the matched embeddings to the LLM input, along with the question itself\n",
    "- run the LLM\n",
    "\n",
    "Note that a lot hinges on the matched embeddings. If the answer to a question is not contained in the matched embeddings, the LLM has no way to give a correct answer based on its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tinygrad codebase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took all the Python files from https://github.com/geohot/tinygrad and put them in `data/tinygrad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "tinygrad_path = \"data/tinygrad\"\n",
    "\n",
    "# Collect all Python files in the tinygrad repo\n",
    "loader = DirectoryLoader(tinygrad_path, glob=\"**/*.py\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 documents loaded.\n",
      "data/tinygrad/image.py\n",
      "data/tinygrad/jit.py\n",
      "data/tinygrad/ops_clang.py\n",
      "data/tinygrad/tensor.py\n",
      "data/tinygrad/ops.py\n",
      "data/tinygrad/shapetracker.py\n",
      "data/tinygrad/mlops.py\n",
      "data/tinygrad/ops_cpu.py\n",
      "data/tinygrad/helpers.py\n",
      "data/tinygrad/symbolic.py\n",
      "data/tinygrad/cstyle.py\n",
      "data/tinygrad/llvmir.py\n",
      "data/tinygrad/ops_gpu.py\n",
      "data/tinygrad/__init__.py\n",
      "data/tinygrad/graph.py\n",
      "data/tinygrad/lazy.py\n",
      "data/tinygrad/lib.py\n",
      "data/tinygrad/ops_llvm.py\n",
      "data/tinygrad/ops_cuda.py\n",
      "data/tinygrad/linearizer.py\n",
      "data/tinygrad/ops_metal.py\n",
      "data/tinygrad/ops_torch.py\n",
      "data/tinygrad/optim.py\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(documents)} documents loaded.\")\n",
    "for doc in documents:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1459, which is longer than the specified 500\n",
      "Created a chunk of size 685, which is longer than the specified 500\n",
      "Created a chunk of size 609, which is longer than the specified 500\n",
      "Created a chunk of size 1005, which is longer than the specified 500\n",
      "Created a chunk of size 1959, which is longer than the specified 500\n",
      "Created a chunk of size 517, which is longer than the specified 500\n",
      "Created a chunk of size 540, which is longer than the specified 500\n",
      "Created a chunk of size 587, which is longer than the specified 500\n",
      "Created a chunk of size 2511, which is longer than the specified 500\n",
      "Created a chunk of size 1064, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 1056, which is longer than the specified 500\n",
      "Created a chunk of size 924, which is longer than the specified 500\n",
      "Created a chunk of size 604, which is longer than the specified 500\n",
      "Created a chunk of size 655, which is longer than the specified 500\n",
      "Created a chunk of size 1247, which is longer than the specified 500\n",
      "Created a chunk of size 1169, which is longer than the specified 500\n",
      "Created a chunk of size 1199, which is longer than the specified 500\n",
      "Created a chunk of size 1407, which is longer than the specified 500\n",
      "Created a chunk of size 901, which is longer than the specified 500\n",
      "Created a chunk of size 557, which is longer than the specified 500\n",
      "Created a chunk of size 510, which is longer than the specified 500\n",
      "Created a chunk of size 847, which is longer than the specified 500\n",
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 643, which is longer than the specified 500\n",
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n",
      "Created a chunk of size 1124, which is longer than the specified 500\n",
      "Created a chunk of size 534, which is longer than the specified 500\n",
      "Created a chunk of size 914, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 1763, which is longer than the specified 500\n",
      "Created a chunk of size 1632, which is longer than the specified 500\n",
      "Created a chunk of size 565, which is longer than the specified 500\n",
      "Created a chunk of size 816, which is longer than the specified 500\n",
      "Created a chunk of size 583, which is longer than the specified 500\n",
      "Created a chunk of size 5008, which is longer than the specified 500\n",
      "Created a chunk of size 503, which is longer than the specified 500\n",
      "Created a chunk of size 547, which is longer than the specified 500\n",
      "Created a chunk of size 948, which is longer than the specified 500\n",
      "Created a chunk of size 1256, which is longer than the specified 500\n",
      "Created a chunk of size 1471, which is longer than the specified 500\n",
      "Created a chunk of size 706, which is longer than the specified 500\n",
      "Created a chunk of size 1132, which is longer than the specified 500\n",
      "Created a chunk of size 1008, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 594, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 877, which is longer than the specified 500\n",
      "Created a chunk of size 887, which is longer than the specified 500\n",
      "Created a chunk of size 572, which is longer than the specified 500\n",
      "Created a chunk of size 1094, which is longer than the specified 500\n",
      "Created a chunk of size 853, which is longer than the specified 500\n",
      "Created a chunk of size 770, which is longer than the specified 500\n",
      "Created a chunk of size 1215, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 597, which is longer than the specified 500\n",
      "Created a chunk of size 788, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 580, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 832, which is longer than the specified 500\n",
      "Created a chunk of size 650, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 581, which is longer than the specified 500\n",
      "Created a chunk of size 669, which is longer than the specified 500\n",
      "Created a chunk of size 753, which is longer than the specified 500\n",
      "Created a chunk of size 822, which is longer than the specified 500\n",
      "Created a chunk of size 624, which is longer than the specified 500\n",
      "Created a chunk of size 537, which is longer than the specified 500\n",
      "Created a chunk of size 505, which is longer than the specified 500\n",
      "Created a chunk of size 1696, which is longer than the specified 500\n",
      "Created a chunk of size 847, which is longer than the specified 500\n",
      "Created a chunk of size 675, which is longer than the specified 500\n",
      "Created a chunk of size 783, which is longer than the specified 500\n",
      "Created a chunk of size 583, which is longer than the specified 500\n",
      "Created a chunk of size 594, which is longer than the specified 500\n",
      "Created a chunk of size 515, which is longer than the specified 500\n",
      "Created a chunk of size 502, which is longer than the specified 500\n",
      "Created a chunk of size 971, which is longer than the specified 500\n",
      "Created a chunk of size 1445, which is longer than the specified 500\n",
      "Created a chunk of size 848, which is longer than the specified 500\n",
      "Created a chunk of size 880, which is longer than the specified 500\n",
      "Created a chunk of size 503, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "docsearch = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever()\n",
    "# Settings from https://python.langchain.com/en/latest/use_cases/code/code-analysis-deeplake.html\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 20\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# query = \"What does the Tensor class represent?\"\n",
    "# query = \"What happens when you call `detach()` on a Tensor?\"\n",
    "# query = \"How does the Tensor.stack() method work?\"\n",
    "# query = \"What classes inherit from the Function class?\"\n",
    "\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0) # 'ada' 'gpt-3.5-turbo' 'gpt-4',\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)\n",
    "# qa({\"question\": query, \"chat_history\": []})\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever )\n",
    "# qa.run(query)\n",
    "\n",
    "# docs = docsearch.similarity_search(query)\n",
    "# docs = docsearch.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What classes are derived from the Function class? \n",
      "\n",
      "**Answer**: The Sin and Relu classes are derived from the Function class. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    # \"What does the Tensor class represent?\",\n",
    "    # \"What happens when you call `detach()` on a Tensor?\",\n",
    "    # \"How does the Tensor.stack() method work?\",\n",
    "    \"What classes are derived from the Function class?\",\n",
    "    # \"What classes and functions in the ./langchain/utilities/ forlder are not covered by unit tests?\",\n",
    "    # \"What one improvement do you propose in code in relation to the class herarchy for the Chain class?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
